{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014923,
     "end_time": "2021-02-06T01:14:40.700485",
     "exception": false,
     "start_time": "2021-02-06T01:14:40.685562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Chest X-ray Abnormalities Detection (PREDICTION)\n",
    "\n",
    "**ECE-GY 9123 | Deep Learning**\n",
    "\n",
    "**Spring 2021**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEAM MEMBERS**\n",
    "\n",
    "**Kunwar Srivastav** (kss519)\n",
    "\n",
    "**Sagar Patel** (sp5894)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "\n",
    "This Notebook is the second part of the project where we discuss the prediction using `detectron2`.\n",
    "\n",
    "Most of the prediction techniques have been inspired from implementations by other profiles on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013265,
     "end_time": "2021-02-06T01:14:40.727572",
     "exception": false,
     "start_time": "2021-02-06T01:14:40.714307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Dataset preparation](#Dataset-preparation)\n",
    "- [Re-installing detectron2](#Re-installing-detectron2)\n",
    "- [Implementing Prediction methods](#Implementing-Prediction-methods)\n",
    "    - [Data preparation](#Data-preparation)\n",
    "    - [Loading the data](#Loading-the-data)\n",
    "- [Predictions file and outputs](#Predictions-file-and-outputs)\n",
    "    - [Creating submission.csv](#Creating-submission.csv)\n",
    "- [Potential extensions](#Potential-extensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013207,
     "end_time": "2021-02-06T01:14:40.754198",
     "exception": false,
     "start_time": "2021-02-06T01:14:40.740991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:14:40.791339Z",
     "iopub.status.busy": "2021-02-06T01:14:40.790766Z",
     "iopub.status.idle": "2021-02-06T01:14:49.356986Z",
     "shell.execute_reply": "2021-02-06T01:14:49.356148Z"
    },
    "papermill": {
     "duration": 8.589343,
     "end_time": "2021-02-06T01:14:49.357094",
     "exception": false,
     "start_time": "2021-02-06T01:14:40.767751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "from plotly import tools, subplots\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "pd.set_option('max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014503,
     "end_time": "2021-02-06T01:14:49.387151",
     "exception": false,
     "start_time": "2021-02-06T01:14:49.372648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Re-installing detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:14:50.133826Z",
     "iopub.status.busy": "2021-02-06T01:14:50.133036Z",
     "iopub.status.idle": "2021-02-06T01:14:50.765558Z",
     "shell.execute_reply": "2021-02-06T01:14:50.765014Z"
    },
    "papermill": {
     "duration": 0.651732,
     "end_time": "2021-02-06T01:14:50.765678",
     "exception": false,
     "start_time": "2021-02-06T01:14:50.113946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\r\n",
      "Built on Wed_Oct_23_19:24:38_PDT_2019\r\n",
      "Cuda compilation tools, release 10.2, V10.2.89\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:14:50.802267Z",
     "iopub.status.busy": "2021-02-06T01:14:50.801623Z",
     "iopub.status.idle": "2021-02-06T01:14:51.901525Z",
     "shell.execute_reply": "2021-02-06T01:14:51.900640Z"
    },
    "papermill": {
     "duration": 1.119558,
     "end_time": "2021-02-06T01:14:51.901633",
     "exception": false,
     "start_time": "2021-02-06T01:14:50.782075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:14:51.976908Z",
     "iopub.status.busy": "2021-02-06T01:14:51.970938Z",
     "iopub.status.idle": "2021-02-06T01:15:17.686057Z",
     "shell.execute_reply": "2021-02-06T01:15:17.685027Z"
    },
    "papermill": {
     "duration": 25.735546,
     "end_time": "2021-02-06T01:15:17.686167",
     "exception": false,
     "start_time": "2021-02-06T01:14:51.950621",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.7/index.html\r\n",
      "Collecting detectron2\r\n",
      "  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.7/detectron2-0.3%2Bcu102-cp37-cp37m-linux_x86_64.whl (6.8 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 73.1 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from detectron2) (0.8.7)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.7/site-packages (from detectron2) (1.1.0)\r\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from detectron2) (2.4.0)\r\n",
      "Requirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.7/site-packages (from detectron2) (8.0.1)\r\n",
      "Requirement already satisfied: pydot in /opt/conda/lib/python3.7/site-packages (from detectron2) (1.4.1)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from detectron2) (1.6.0)\r\n",
      "Requirement already satisfied: yacs>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from detectron2) (0.1.8)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from detectron2) (0.18.2)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from detectron2) (3.2.1)\r\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.7/site-packages (from detectron2) (4.45.0)\r\n",
      "Collecting fvcore>=0.1.2\r\n",
      "  Downloading fvcore-0.1.3.post20210204.tar.gz (35 kB)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fvcore>=0.1.2->detectron2) (1.18.5)\r\n",
      "Requirement already satisfied: yacs>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from detectron2) (0.1.8)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from fvcore>=0.1.2->detectron2) (5.3.1)\r\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.7/site-packages (from detectron2) (4.45.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.7/site-packages (from detectron2) (1.1.0)\r\n",
      "Requirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.7/site-packages (from detectron2) (8.0.1)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from detectron2) (0.8.7)\r\n",
      "Collecting iopath>=0.1.2\r\n",
      "  Downloading iopath-0.1.3.tar.gz (10 kB)\r\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.7/site-packages (from detectron2) (4.45.0)\r\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from iopath>=0.1.2->fvcore>=0.1.2->detectron2) (2.0.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2) (2.8.1)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2) (2.4.7)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2) (1.2.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fvcore>=0.1.2->detectron2) (1.18.5)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->detectron2) (1.14.0)\r\n",
      "Collecting pycocotools>=2.0.2\r\n",
      "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\r\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->detectron2) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->detectron2) (0.29.21)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from detectron2) (3.2.1)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2) (2.4.7)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->detectron2) (1.14.0)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (1.23.0)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (1.0.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->detectron2) (1.14.0)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (0.34.2)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (3.2.1)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (1.7.0)\r\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->detectron2) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (2.23.0)\r\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (3.14.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fvcore>=0.1.2->detectron2) (1.18.5)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (0.10.0)\r\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (1.34.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (0.4.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->detectron2) (1.14.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->detectron2) (1.14.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (4.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (0.2.7)\r\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->detectron2) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2) (3.1.1)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (1.23.0)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.2.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->detectron2) (1.14.0)\r\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->detectron2) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->detectron2) (1.14.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.25.9)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.9)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2020.12.5)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.0.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2) (2.23.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2) (0.4.8)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from fvcore>=0.1.2->detectron2) (5.3.1)\r\n",
      "Building wheels for collected packages: fvcore, iopath, pycocotools\r\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.3.post20210204-py3-none-any.whl size=44946 sha256=cebd71157a8c63796dd572aa0d25b0c30d288bfad63f3588790ab331d761d912\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/f2/8c/124367ec901d4b48b5ba4c0226c0a8239815b4e969ad15cc7a\r\n",
      "  Building wheel for iopath (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.3-py3-none-any.whl size=11169 sha256=4cc6176d7d4d20d3d74fa93127008acf6c3e0a6734d7fd12c2b4fb62d2c674ee\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/33/44/20/06445612ad8cf4ad6250aee85516e9499d5a49151ef5358164\r\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl size=273765 sha256=8c7b0e703bfde63e0c0cb0867ddeb6a26fa0d28d079ca6d26513f8602193ad7b\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/cf/1b/e95c99c5f9d1648be3f500ca55e7ce55f24818b0f48336adaf\r\n",
      "Successfully built fvcore iopath pycocotools\r\n",
      "Installing collected packages: iopath, pycocotools, fvcore, detectron2\r\n",
      "Successfully installed detectron2-0.3+cu102 fvcore-0.1.3.post20210204 iopath-0.1.3 pycocotools-2.0.2\r\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.7/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030375,
     "end_time": "2021-02-06T01:15:17.747895",
     "exception": false,
     "start_time": "2021-02-06T01:15:17.717520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Implementing Prediction methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030117,
     "end_time": "2021-02-06T01:15:17.808496",
     "exception": false,
     "start_time": "2021-02-06T01:15:17.778379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:15:17.888122Z",
     "iopub.status.busy": "2021-02-06T01:15:17.882822Z",
     "iopub.status.idle": "2021-02-06T01:15:18.420851Z",
     "shell.execute_reply": "2021-02-06T01:15:18.419793Z"
    },
    "papermill": {
     "duration": 0.582391,
     "end_time": "2021-02-06T01:15:18.420967",
     "exception": false,
     "start_time": "2021-02-06T01:15:17.838576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from detectron2.structures import BoxMode\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_vinbigdata_dicts(\n",
    "    imgdir: Path,\n",
    "    train_df: pd.DataFrame,\n",
    "    train_data_type: str = \"original\",\n",
    "    use_cache: bool = True,\n",
    "    debug: bool = True,\n",
    "    target_indices: Optional[np.ndarray] = None,\n",
    "    use_class14: bool = False,\n",
    "):\n",
    "    debug_str = f\"_debug{int(debug)}\"\n",
    "    train_data_type_str = f\"_{train_data_type}\"\n",
    "    class14_str = f\"_14class{int(use_class14)}\"\n",
    "    cache_path = Path(\".\") / f\"dataset_dicts_cache{train_data_type_str}{class14_str}{debug_str}.pkl\"\n",
    "    if not use_cache or not cache_path.exists():\n",
    "        print(\"Creating data...\")\n",
    "        train_meta = pd.read_csv(imgdir / \"train_meta.csv\")\n",
    "        if debug:\n",
    "            train_meta = train_meta.iloc[:500]\n",
    "\n",
    "        # Load one image to get the size of the image\n",
    "        image_id = train_meta.loc[0, \"image_id\"]\n",
    "        image_path = str(imgdir / \"train\" / f\"{image_id}.png\")\n",
    "        image = cv2.imread(image_path)\n",
    "        resized_height, resized_width, ch = image.shape\n",
    "        print(f\"image shape: {image.shape}\")\n",
    "\n",
    "        dataset_dicts = []\n",
    "        for index, train_meta_row in tqdm(train_meta.iterrows(), total=len(train_meta)):\n",
    "            record = {}\n",
    "\n",
    "            image_id, height, width = train_meta_row.values\n",
    "            filename = str(imgdir / \"train\" / f\"{image_id}.png\")\n",
    "            record[\"file_name\"] = filename\n",
    "            record[\"image_id\"] = image_id\n",
    "            record[\"height\"] = resized_height\n",
    "            record[\"width\"] = resized_width\n",
    "            objs = []\n",
    "            for index2, row in train_df.query(\"image_id == @image_id\").iterrows():\n",
    "                class_id = row[\"class_id\"]\n",
    "                if class_id == 14:\n",
    "                    if use_class14:\n",
    "                        bbox_resized = [0, 0, resized_width, resized_height]\n",
    "                        obj = {\n",
    "                            \"bbox\": bbox_resized,\n",
    "                            \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                            \"category_id\": class_id,\n",
    "                        }\n",
    "                        objs.append(obj)\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    h_ratio = resized_height / height\n",
    "                    w_ratio = resized_width / width\n",
    "                    bbox_resized = [\n",
    "                        float(row[\"x_min\"]) * w_ratio,\n",
    "                        float(row[\"y_min\"]) * h_ratio,\n",
    "                        float(row[\"x_max\"]) * w_ratio,\n",
    "                        float(row[\"y_max\"]) * h_ratio,\n",
    "                    ]\n",
    "                    obj = {\n",
    "                        \"bbox\": bbox_resized,\n",
    "                        \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                        \"category_id\": class_id,\n",
    "                    }\n",
    "                    objs.append(obj)\n",
    "            record[\"annotations\"] = objs\n",
    "            dataset_dicts.append(record)\n",
    "        with open(cache_path, mode=\"wb\") as f:\n",
    "            pickle.dump(dataset_dicts, f)\n",
    "\n",
    "    print(f\"Load from cache {cache_path}\")\n",
    "    with open(cache_path, mode=\"rb\") as f:\n",
    "        dataset_dicts = pickle.load(f)\n",
    "    if target_indices is not None:\n",
    "        dataset_dicts = [dataset_dicts[i] for i in target_indices]\n",
    "    return dataset_dicts\n",
    "\n",
    "\n",
    "def get_vinbigdata_dicts_test(\n",
    "    imgdir: Path, test_meta: pd.DataFrame, use_cache: bool = True, debug: bool = True,\n",
    "):\n",
    "    debug_str = f\"_debug{int(debug)}\"\n",
    "    cache_path = Path(\".\") / f\"dataset_dicts_cache_test{debug_str}.pkl\"\n",
    "    if not use_cache or not cache_path.exists():\n",
    "        print(\"Creating data...\")\n",
    "        if debug:\n",
    "            test_meta = test_meta.iloc[:500]\n",
    "\n",
    "        # Load one image to get the size of the image\n",
    "        image_id = test_meta.loc[0, \"image_id\"]\n",
    "        image_path = str(imgdir / \"test\" / f\"{image_id}.png\")\n",
    "        image = cv2.imread(image_path)\n",
    "        resized_height, resized_width, ch = image.shape\n",
    "        print(f\"image shape: {image.shape}\")\n",
    "\n",
    "        dataset_dicts = []\n",
    "        for index, test_meta_row in tqdm(test_meta.iterrows(), total=len(test_meta)):\n",
    "            record = {}\n",
    "\n",
    "            image_id, height, width = test_meta_row.values\n",
    "            filename = str(imgdir / \"test\" / f\"{image_id}.png\")\n",
    "            record[\"file_name\"] = filename\n",
    "            record[\"image_id\"] = image_id\n",
    "            record[\"height\"] = resized_height\n",
    "            record[\"width\"] = resized_width\n",
    "            dataset_dicts.append(record)\n",
    "        with open(cache_path, mode=\"wb\") as f:\n",
    "            pickle.dump(dataset_dicts, f)\n",
    "\n",
    "    print(f\"Load from cache {cache_path}\")\n",
    "    with open(cache_path, mode=\"rb\") as f:\n",
    "        dataset_dicts = pickle.load(f)\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030425,
     "end_time": "2021-02-06T01:15:18.482512",
     "exception": false,
     "start_time": "2021-02-06T01:15:18.452087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**REFERENCES:**\n",
    "\n",
    "- [The function predict_batch](https://github.com/sphinx-doc/sphinx/issues/4258)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:15:18.558789Z",
     "iopub.status.busy": "2021-02-06T01:15:18.557892Z",
     "iopub.status.idle": "2021-02-06T01:15:18.660026Z",
     "shell.execute_reply": "2021-02-06T01:15:18.659107Z"
    },
    "papermill": {
     "duration": 0.146868,
     "end_time": "2021-02-06T01:15:18.660146",
     "exception": false,
     "start_time": "2021-02-06T01:15:18.513278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import cv2\n",
    "import detectron2\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "import pandas as pd\n",
    "import torch\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def format_pred(labels: ndarray, boxes: ndarray, scores: ndarray) -> str:\n",
    "    pred_strings = []\n",
    "    for label, score, bbox in zip(labels, scores, boxes):\n",
    "        xmin, ymin, xmax, ymax = bbox.astype(np.int64)\n",
    "        pred_strings.append(f\"{label} {score} {xmin} {ymin} {xmax} {ymax}\")\n",
    "    return \" \".join(pred_strings)\n",
    "\n",
    "\n",
    "def predict_batch(predictor: DefaultPredictor, im_list: List[ndarray]) -> List:\n",
    "    with torch.no_grad():\n",
    "        inputs_list = []\n",
    "        for original_image in im_list:\n",
    "            # Apply pre-processing to the image\n",
    "            if predictor.input_format == \"RGB\":\n",
    "                original_image = original_image[:, :, ::-1]\n",
    "            height, width = original_image.shape[:2]\n",
    "            image = original_image\n",
    "            image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "            inputs = {\"image\": image, \"height\": height, \"width\": width}\n",
    "            inputs_list.append(inputs)\n",
    "        predictions = predictor.model(inputs_list)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:15:18.728927Z",
     "iopub.status.busy": "2021-02-06T01:15:18.728237Z",
     "iopub.status.idle": "2021-02-06T01:15:18.731353Z",
     "shell.execute_reply": "2021-02-06T01:15:18.730916Z"
    },
    "papermill": {
     "duration": 0.040308,
     "end_time": "2021-02-06T01:15:18.731448",
     "exception": false,
     "start_time": "2021-02-06T01:15:18.691140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Necessary Utility libraries\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Any, Union\n",
    "\n",
    "import yaml\n",
    "\n",
    "\n",
    "def save_yaml(filepath: Union[str, Path], content: Any, width: int = 120):\n",
    "    with open(filepath, \"w\") as f:\n",
    "        yaml.dump(content, f, width=width)\n",
    "\n",
    "\n",
    "def load_yaml(filepath: Union[str, Path]) -> Any:\n",
    "    with open(filepath, \"r\") as f:\n",
    "        content = yaml.full_load(f)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T01:15:18.798362Z",
     "iopub.status.busy": "2021-02-06T01:15:18.797588Z",
     "iopub.status.idle": "2021-02-06T01:15:18.800281Z",
     "shell.execute_reply": "2021-02-06T01:15:18.799875Z"
    },
    "papermill": {
     "duration": 0.038382,
     "end_time": "2021-02-06T01:15:18.800387",
     "exception": false,
     "start_time": "2021-02-06T01:15:18.762005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Confguring all the classes\n",
    "\n",
    "thing_classes = [\n",
    "    \"Aortic enlargement\",\n",
    "    \"Atelectasis\",\n",
    "    \"Calcification\",\n",
    "    \"Cardiomegaly\",\n",
    "    \"Consolidation\",\n",
    "    \"ILD\",\n",
    "    \"Infiltration\",\n",
    "    \"Lung Opacity\",\n",
    "    \"Nodule/Mass\",\n",
    "    \"Other lesion\",\n",
    "    \"Pleural effusion\",\n",
    "    \"Pleural thickening\",\n",
    "    \"Pneumothorax\",\n",
    "    \"Pulmonary fibrosis\"\n",
    "]\n",
    "category_name_to_id = {class_name: index for index, class_name in enumerate(thing_classes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-02-06T01:15:18.934748Z",
     "iopub.status.busy": "2021-02-06T01:15:18.933968Z",
     "iopub.status.idle": "2021-02-06T01:15:18.936638Z",
     "shell.execute_reply": "2021-02-06T01:15:18.936201Z"
    },
    "papermill": {
     "duration": 0.044023,
     "end_time": "2021-02-06T01:15:18.936724",
     "exception": false,
     "start_time": "2021-02-06T01:15:18.892701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Flags\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Flags:\n",
    "    debug: bool = True\n",
    "    outdir: str = \"results/det\"\n",
    "\n",
    "    # Data configurations\n",
    "    imgdir_name: str = \"vinbigdata-chest-xray-resized-png-256x256\"\n",
    "    split_mode: str = \"all_train\"\n",
    "    seed: int = 111\n",
    "    train_data_type: str = \"original\"\n",
    "    use_class14: bool = False\n",
    "\n",
    "    # Training configurations\n",
    "    iter: int = 10000\n",
    "    ims_per_batch: int = 2\n",
    "    num_workers: int = 4\n",
    "    lr_scheduler_name: str = \"WarmupMultiStepLR\"\n",
    "    base_lr: float = 0.00025\n",
    "    roi_batch_size_per_image: int = 512\n",
    "    eval_period: int = 10000\n",
    "    aug_kwargs: Dict = field(default_factory=lambda: {})\n",
    "\n",
    "    def update(self, param_dict: Dict) -> \"Flags\":\n",
    "        for key, value in param_dict.items():\n",
    "            if not hasattr(self, key):\n",
    "                raise ValueError(f\"[ERROR] Unexpected key for flag = {key}\")\n",
    "            setattr(self, key, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.062839,
     "end_time": "2021-02-06T01:15:19.030588",
     "exception": false,
     "start_time": "2021-02-06T01:15:18.967749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predictions file and outputs\n",
    "\n",
    "All the methods that needed to be intializaed have been initialized\n",
    "\n",
    "Referred from Multiple Kaggle Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T01:15:19.099562Z",
     "iopub.status.busy": "2021-02-06T01:15:19.099024Z",
     "iopub.status.idle": "2021-02-06T01:15:19.151049Z",
     "shell.execute_reply": "2021-02-06T01:15:19.150450Z"
    },
    "papermill": {
     "duration": 0.089808,
     "end_time": "2021-02-06T01:15:19.151183",
     "exception": false,
     "start_time": "2021-02-06T01:15:19.061375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flags Flags(debug=False, outdir='results/20210125_all_alb_aug_512_cos', imgdir_name='vinbigdata-chest-xray-resized-png-512x512', split_mode='all_train', seed=111, train_data_type='original', use_class14=False, iter=30000, ims_per_batch=2, num_workers=4, lr_scheduler_name='WarmupCosineLR', base_lr=0.001, roi_batch_size_per_image=512, eval_period=2000, aug_kwargs={'HorizontalFlip': {'p': 0.5}, 'RandomBrightnessContrast': {'p': 0.5}, 'ShiftScaleRotate': {'p': 0.5, 'rotate_limit': 10, 'scale_limit': 0.15}})\n"
     ]
    }
   ],
   "source": [
    "inputdir = Path(\"/kaggle/input\")\n",
    "traineddir = inputdir / \"vinbigdata-alb-aug-512-cos\"\n",
    "\n",
    "# Flags\n",
    "flags: Flags = Flags().update(load_yaml(str(traineddir/\"flags.yaml\")))\n",
    "print(\"flags\", flags)\n",
    "debug = flags.debug\n",
    "outdir = Path(flags.outdir)\n",
    "os.makedirs(str(outdir), exist_ok=True)\n",
    "\n",
    "# Reading the data\n",
    "datadir = inputdir / \"vinbigdata-chest-xray-abnormalities-detection\"\n",
    "if flags.imgdir_name == \"vinbigdata-chest-xray-resized-png-512x512\":\n",
    "    imgdir = inputdir/ \"vinbigdata\"\n",
    "else:\n",
    "    imgdir = inputdir / flags.imgdir_name\n",
    "\n",
    "# Reading in the data CSV files\n",
    "test_meta = pd.read_csv(inputdir / \"vinbigdata-testmeta\" / \"test_meta.csv\")\n",
    "sample_submission = pd.read_csv(datadir / \"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T01:15:19.241650Z",
     "iopub.status.busy": "2021-02-06T01:15:19.240750Z",
     "iopub.status.idle": "2021-02-06T01:18:09.029757Z",
     "shell.execute_reply": "2021-02-06T01:18:09.030176Z"
    },
    "papermill": {
     "duration": 169.846964,
     "end_time": "2021-02-06T01:18:09.030345",
     "exception": false,
     "start_time": "2021-02-06T01:15:19.183381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cfg.OUTPUT_DIR ./output -> results/20210125_all_alb_aug_512_cos\n",
      "Original thresh 0.05\n",
      "Changed  thresh 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1105/3000 [00:00<00:00, 11045.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data...\n",
      "image shape: (512, 512, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:00<00:00, 10825.12it/s]\n",
      "  0%|          | 0/750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from cache dataset_dicts_cache_test_debug0.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:124: UserWarning:\n",
      "\n",
      "This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729138878/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "\n",
      "100%|██████████| 750/750 [02:37<00:00,  4.77it/s]\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "original_output_dir = cfg.OUTPUT_DIR\n",
    "cfg.OUTPUT_DIR = str(outdir)\n",
    "print(f\"cfg.OUTPUT_DIR {original_output_dir} -> {cfg.OUTPUT_DIR}\")\n",
    "\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"vinbigdata_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "\n",
    "# Let the training initialize from the MODEL ZOO\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = flags.base_lr\n",
    "cfg.SOLVER.MAX_ITER = flags.iter\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = flags.roi_batch_size_per_image\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(thing_classes)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "cfg.MODEL.WEIGHTS = str(traineddir/\"model_final.pth\")\n",
    "print(\"Original thresh\", cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.0\n",
    "print(\"Changed  thresh\", cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST)\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "DatasetCatalog.register(\n",
    "    \"vinbigdata_test\", lambda: get_vinbigdata_dicts_test(imgdir, test_meta, debug=debug)\n",
    ")\n",
    "MetadataCatalog.get(\"vinbigdata_test\").set(thing_classes=thing_classes)\n",
    "metadata = MetadataCatalog.get(\"vinbigdata_test\")\n",
    "dataset_dicts = get_vinbigdata_dicts_test(imgdir, test_meta, debug=debug)\n",
    "\n",
    "if debug:\n",
    "    dataset_dicts = dataset_dicts[:100]\n",
    "\n",
    "results_list = []\n",
    "index = 0\n",
    "batch_size = 4\n",
    "\n",
    "for i in tqdm(range(ceil(len(dataset_dicts) / batch_size))):\n",
    "    inds = list(range(batch_size * i, min(batch_size * (i + 1), len(dataset_dicts))))\n",
    "    dataset_dicts_batch = [dataset_dicts[i] for i in inds]\n",
    "    im_list = [cv2.imread(d[\"file_name\"]) for d in dataset_dicts_batch]\n",
    "    outputs_list = predict_batch(predictor, im_list)\n",
    "\n",
    "    for im, outputs, d in zip(im_list, outputs_list, dataset_dicts_batch):\n",
    "        resized_height, resized_width, ch = im.shape\n",
    "        if index < 5:\n",
    "            v = Visualizer(\n",
    "                im[:, :, ::-1],\n",
    "                metadata=metadata,\n",
    "                scale=0.5,\n",
    "                instance_mode=ColorMode.IMAGE_BW\n",
    "            )\n",
    "            out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "            cv2.imwrite(str(outdir / f\"pred_{index}.jpg\"), out.get_image()[:, :, ::-1])\n",
    "\n",
    "        image_id, dim0, dim1 = test_meta.iloc[index].values\n",
    "\n",
    "        instances = outputs[\"instances\"]\n",
    "        if len(instances) == 0:\n",
    "            # No finding, let us initialize [14 1 0 0 1 1]\n",
    "            result = {\"image_id\": image_id, \"PredictionString\": \"14 1.0 0 0 1 1\"}\n",
    "        else:\n",
    "            fields: Dict[str, Any] = instances.get_fields()\n",
    "            pred_classes = fields[\"pred_classes\"]\n",
    "            pred_scores = fields[\"scores\"]\n",
    "            pred_boxes = fields[\"pred_boxes\"].tensor\n",
    "\n",
    "            h_ratio = dim0 / resized_height\n",
    "            w_ratio = dim1 / resized_width\n",
    "            pred_boxes[:, [0, 2]] *= w_ratio\n",
    "            pred_boxes[:, [1, 3]] *= h_ratio\n",
    "\n",
    "            pred_classes_array = pred_classes.cpu().numpy()\n",
    "            pred_boxes_array = pred_boxes.cpu().numpy()\n",
    "            pred_scores_array = pred_scores.cpu().numpy()\n",
    "\n",
    "            result = {\n",
    "                \"image_id\": image_id,\n",
    "                \"PredictionString\": format_pred(\n",
    "                    pred_classes_array, pred_boxes_array, pred_scores_array\n",
    "                ),\n",
    "            }\n",
    "        results_list.append(result)\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating submission.csv\n",
    "\n",
    "As per the Kaggle rules, it was asked to show the outputs in the CSV format. So we decided to follow the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-06T01:18:09.984011Z",
     "iopub.status.busy": "2021-02-06T01:18:09.983235Z",
     "iopub.status.idle": "2021-02-06T01:18:10.623768Z",
     "shell.execute_reply": "2021-02-06T01:18:10.624195Z"
    },
    "papermill": {
     "duration": 0.885336,
     "end_time": "2021-02-06T01:18:10.624332",
     "exception": false,
     "start_time": "2021-02-06T01:18:09.738996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8dec5497ecc246766acfba5a4be4e619</td>\n",
       "      <td>0 0.775484561920166 1010 603 1248 893 13 0.501...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>287422bed1d9d153387361889619abed</td>\n",
       "      <td>3 0.9862767457962036 666 1289 1865 1820 0 0.78...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1d12b94b7acbeadef7d7700b50aa90d4</td>\n",
       "      <td>0 0.8117097616195679 1173 896 1433 1138 3 0.78...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6b872791e23742f6c33a08fc24f77365</td>\n",
       "      <td>11 0.3285936415195465 1799 2196 1900 2336 10 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d0d2addff91ad7beb1d92126ff74d621</td>\n",
       "      <td>0 0.850891649723053 1422 828 1707 1140 3 0.741...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>78b44b96b121d6075d7ae27135278e03</td>\n",
       "      <td>0 0.5035402178764343 1036 771 1214 949 11 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>afee8ff90f29b8827d0eb78774d25324</td>\n",
       "      <td>0 0.27024954557418823 1028 714 1243 947 11 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>6e07fab2014be723250f7897ab6e3df2</td>\n",
       "      <td>0 0.990529477596283 1667 801 1972 1131 3 0.977...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>690bb572300ef08bbbb7ebf4196099cf</td>\n",
       "      <td>0 0.5590820908546448 1085 689 1337 956 8 0.464...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0a08191a658edb1327e7282045ec71cf</td>\n",
       "      <td>11 0.45100387930870056 565 379 797 479 11 0.16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              image_id  \\\n",
       "0     8dec5497ecc246766acfba5a4be4e619   \n",
       "1     287422bed1d9d153387361889619abed   \n",
       "2     1d12b94b7acbeadef7d7700b50aa90d4   \n",
       "3     6b872791e23742f6c33a08fc24f77365   \n",
       "4     d0d2addff91ad7beb1d92126ff74d621   \n",
       "...                                ...   \n",
       "2995  78b44b96b121d6075d7ae27135278e03   \n",
       "2996  afee8ff90f29b8827d0eb78774d25324   \n",
       "2997  6e07fab2014be723250f7897ab6e3df2   \n",
       "2998  690bb572300ef08bbbb7ebf4196099cf   \n",
       "2999  0a08191a658edb1327e7282045ec71cf   \n",
       "\n",
       "                                       PredictionString  \n",
       "0     0 0.775484561920166 1010 603 1248 893 13 0.501...  \n",
       "1     3 0.9862767457962036 666 1289 1865 1820 0 0.78...  \n",
       "2     0 0.8117097616195679 1173 896 1433 1138 3 0.78...  \n",
       "3     11 0.3285936415195465 1799 2196 1900 2336 10 0...  \n",
       "4     0 0.850891649723053 1422 828 1707 1140 3 0.741...  \n",
       "...                                                 ...  \n",
       "2995  0 0.5035402178764343 1036 771 1214 949 11 0.10...  \n",
       "2996  0 0.27024954557418823 1028 714 1243 947 11 0.0...  \n",
       "2997  0 0.990529477596283 1667 801 1972 1131 3 0.977...  \n",
       "2998  0 0.5590820908546448 1085 689 1337 956 8 0.464...  \n",
       "2999  11 0.45100387930870056 565 379 797 479 11 0.16...  \n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_det = pd.DataFrame(results_list, columns=['image_id', 'PredictionString'])\n",
    "submission_det.to_csv(outdir/\"submission.csv\", index=False)\n",
    "submission_det"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.237073,
     "end_time": "2021-02-06T01:18:11.575869",
     "exception": false,
     "start_time": "2021-02-06T01:18:11.338796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Potential extensions\n",
    "\n",
    "- It is no surprise that there is a lot of room for improvement in this project. In some cases, maybe running a 2-class classifier would make it more accurate and we might not have such a low confidence score.\n",
    "- It would probably be better to try **including \"No finding\" class during detection training** (by adding virtual \"No finding\" boxes, or by adding global classifier together with the detection).\n",
    "- Making it open to alien data and creating an application out of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.237092,
     "end_time": "2021-02-06T01:18:12.526004",
     "exception": false,
     "start_time": "2021-02-06T01:18:12.288912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "papermill": {
   "duration": 216.743164,
   "end_time": "2021-02-06T01:18:13.273240",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-06T01:14:36.530076",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
